# Home.py (ä¿®æ­£ç‰ˆï¼Œè§£æ±ºåŸ·è¡Œç·’é–“ session_state çš„å•é¡Œ)

import streamlit as st
import os
import json
import time
import requests
from datetime import date
import threading

# --- å°å…¥æ ¸å¿ƒè™•ç†å‡½å¼ (ä¸è®Š) ---
from scripts.health_check import check_and_start_ollama
from scripts.inbox_agent import get_content_from_url, get_text_from_image, process_inbox_item
from scripts.knowledge_agent import create_knowledge_node
from scripts.review_agent import generate_periodic_review
from scripts.notion_handler import (
    create_notion_page, format_inbox_properties, format_knowledge_properties,
    query_notion_database, update_notion_page_status, get_page_content_as_text,
    build_date_filter, format_review_properties
)
from scripts.email_handler import send_email, format_knowledge_node_as_html, format_review_as_html

# --- èƒŒæ™¯ä»»å‹™å‡½å¼ ---

# --- æ ¸å¿ƒä¿®æ”¹ 1: èƒŒæ™¯å‡½å¼ç¾åœ¨æ¥æ”¶ä¸€å€‹ status_dict ä½œç‚ºåƒæ•¸ ---
def background_add_to_inbox(config: dict, status_dict: dict, task_type: str, content: str, url: str = None):
    """é€šç”¨æ–¼æ–°å¢åˆ° Inbox çš„èƒŒæ™¯ä»»å‹™ã€‚"""
    try:
        status_dict["running"] = True
        status_dict["message"] = "æ­£åœ¨è™•ç†..."
        
        raw_content = ""
        source_type = task_type
        
        if task_type == 'text':
            raw_content = content
            status_dict["message"] = "ğŸ¤– æ­£åœ¨å‘¼å« AI è™•ç†æ–‡æœ¬..."
        elif task_type == 'url':
            status_dict["message"] = "ğŸ•¸ï¸ æ­£åœ¨æŠ“å–ç¶²é å…§å®¹..."
            raw_content = get_content_from_url(content)
            url = content
        elif task_type == 'image':
            status_dict["message"] = "ğŸ–¼ï¸ æ­£åœ¨é€²è¡Œ OCR è­˜åˆ¥..."
            raw_content = get_text_from_image(content)
            os.remove(content)

        if not raw_content or not raw_content.strip():
            status_dict["error"] = f"âŒ ç„¡æ³•ç²å–å…§å®¹ ({task_type})ã€‚"
            return

        status_dict["message"] = "ğŸ¤– æ­£åœ¨é€²è¡Œæ™ºèƒ½æ‘˜è¦..."
        processed_data = process_inbox_item(raw_content, config)
        if not processed_data:
            status_dict["logs"].append("âš ï¸ AI æ™ºèƒ½è™•ç†å¤±æ•—ï¼Œä½†åŸå§‹ç­†è¨˜ä»æœƒä¿å­˜ã€‚")
            processed_data = {}

        status_dict["message"] = "âœï¸ æ­£åœ¨å¯«å…¥ Notion..."
        properties = format_inbox_properties(processed_data, raw_content, url, source_type=source_type)
        result = create_notion_page(config['NOTION_TOKEN'], config['INBOX_DB_ID'], properties, page_content=raw_content)

        if result:
            status_dict["success"] = "âœ… æˆåŠŸæ–°å¢è‡³ Notion Inboxï¼"
        else:
            status_dict["error"] = "âŒ æ–°å¢è‡³ Notion Inbox å¤±æ•—ã€‚"

    except Exception as e:
        status_dict["error"] = f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}"
    finally:
        status_dict["running"] = False

def background_knowledge_synthesis(config: dict, status_dict: dict):
    """çŸ¥è­˜åˆæˆçš„èƒŒæ™¯ä»»å‹™ã€‚"""
    try:
        # --- æ ¸å¿ƒä¿®æ”¹ 1: åœ¨ status_dict ä¸­åˆå§‹åŒ–ä¸€å€‹æˆåŠŸæ¨™è¨˜ ---
        status_dict["synthesis_happened"] = False
                
        status_dict["logs"].append("æ­£åœ¨æŸ¥è©¢éœ€è¦è™•ç†çš„æ–°é …ç›®...")
        filter_payload = {"property": "Status", "select": {"equals": "New"}}
        new_items = query_notion_database(config['NOTION_TOKEN'], config['INBOX_DB_ID'], filter_payload, config.get("DEBUG_MODE", False))
        
        if not new_items:
            status_dict["logs"].append("âœ… Inbox ä¸­æ²’æœ‰éœ€è¦åˆæˆçš„æ–°é …ç›®ã€‚")
            return

        total_items = len(new_items)
        status_dict["total"] = total_items
        status_dict["logs"].append(f"æ‰¾åˆ° {total_items} å€‹æ–°é …ç›®éœ€è¦è™•ç†ã€‚")

        synthesis_successful = False
        for i, item in enumerate(new_items):
            page_id = item['id']
            status_dict["current_task"] = f"æ­£åœ¨è™•ç†é …ç›® {i+1}/{total_items}..."
            content_to_process, metadata = get_page_content_as_text(config['NOTION_TOKEN'], item)
            
            if not content_to_process.strip():
                status_dict["logs"].append(f"âš ï¸ é …ç›® {page_id} å…§å®¹ç‚ºç©ºï¼Œå·²è·³éã€‚")
                continue

            try:
                status_dict["logs"].append(f"ğŸ§  é …ç›® '{content_to_process[:30]}...': æ­£åœ¨å‘¼å« AI...")
                knowledge_data = create_knowledge_node(content_to_process, config)
                if not knowledge_data:
                    status_dict["logs"].append(f"âŒ AI æœªèƒ½ç”Ÿæˆæœ‰æ•ˆç¯€é»ã€‚")
                    continue

                status_dict["logs"].append(f"âœï¸ æ­£åœ¨å¯«å…¥ Notion: '{knowledge_data.get('title', 'Untitled')}'")
                properties = format_knowledge_properties(knowledge_data, metadata=metadata)
                result = create_notion_page(config['NOTION_TOKEN'], config['KNOWLEDGE_DB_ID'], properties)
                
                if result:
                    status_dict["logs"].append(f"âœ… åˆæˆæˆåŠŸï¼")
                    update_notion_page_status(config['NOTION_TOKEN'], page_id, "Processed")
                    # --- æ ¸å¿ƒä¿®æ”¹ 2: æ›´æ–° status_dict ä¸­çš„æ¨™è¨˜ï¼Œè€Œä¸æ˜¯ session_state ---
                    status_dict["synthesis_happened"] = True
                else:
                    status_dict["logs"].append(f"âŒ å¯«å…¥ Notion å¤±æ•—ï¼")
            except Exception as e:
                status_dict["logs"].append(f"âŒ è™•ç†é …ç›®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            status_dict["progress"] = i + 1
            if i < total_items - 1:
                status_dict["logs"].append("ğŸ”„ ç­‰å¾… 5 ç§’...")
                time.sleep(5)

        # --- æ ¸å¿ƒä¿®æ”¹ 3: ç§»é™¤èˆŠçš„ã€éŒ¯èª¤çš„ session_state å¯«å…¥ ---
        # if synthesis_successful:
        #     st.session_state.data_updated = True # <--- åˆªé™¤é€™ä¸€æ•´å¡Š
        status_dict["current_task"] = "âœ… çŸ¥è­˜åˆæˆæµç¨‹å…¨éƒ¨å®Œæˆï¼"
    except Exception as e:
        status_dict["current_task"] = f"âŒ èƒŒæ™¯ä»»å‹™ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"
    finally:
        status_dict["running"] = False

def background_run_review(config: dict, status_dict: dict, period: str):
    """è¶¨å‹¢åˆ†æçš„èƒŒæ™¯ä»»å‹™ã€‚"""
    try:
        status_dict["running"] = True
        status_dict["message"] = f"ğŸ” æ­£åœ¨å¾ Notion æŠ“å– {period} ç­†è¨˜..."
        date_filter = build_date_filter(period)
        notes = query_notion_database(config['NOTION_TOKEN'], config['KNOWLEDGE_DB_ID'], date_filter, config.get("DEBUG_MODE", False))
        
        if not notes:
            status_dict["success"] = f"âœ… åœ¨æŒ‡å®šæœŸé–“å†…æ²’æœ‰æ‰¾åˆ°æ–°çš„çŸ¥è­˜ç¯€é»ã€‚"
            return

        status_dict["message"] = f"æ‰¾åˆ° {len(notes)} ç¯‡ç­†è¨˜ï¼Œæ­£åœ¨é€²è¡Œæ¿ƒç¸®..."
        consolidated_notes = [f"## {note['properties']['Title']['title'][0]['text']['content']}\n> {note['properties']['Core Idea']['rich_text'][0]['text']['content']}\n" for note in notes]
        consolidated_text = "\n---\n".join(consolidated_notes)
        
        status_dict["message"] = f"ğŸ¤– æ­£åœ¨å‘¼å« AI ç”Ÿæˆ {period} è¶¨å‹¢å ±å‘Š..."
        review_data = generate_periodic_review(consolidated_text, period, config)
        if not review_data:
            status_dict["error"] = "âŒ è¶¨å‹¢åˆ†æå¤±æ•—ï¼ŒAI æœªè¿”å›æœ‰æ•ˆæ•¸æ“šã€‚"
            return

        status_dict["message"] = "âœï¸ æ­£åœ¨å°‡è¶¨å‹¢å ±å‘Šå¯«å…¥ Notion..."
        start_date = date.fromisoformat(date_filter['created_time']['on_or_after'])
        end_date = date.today()
        review_properties = format_review_properties(review_data, period, start_date, end_date)
        result = create_notion_page(config['NOTION_TOKEN'], config['REVIEW_DB_ID'], review_properties)
        
        if result:
            status_dict["success"] = f"âœ… {period.capitalize()} è¶¨å‹¢åˆ†æå ±å‘Šå·²æˆåŠŸç”Ÿæˆï¼"
        else:
            status_dict["error"] = f"âŒ è¶¨å‹¢åˆ†æå ±å‘Šå„²å­˜å¤±æ•—ã€‚"
            
    except Exception as e:
        status_dict["error"] = f"âŒ è¶¨å‹¢åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}"
    finally:
        status_dict["running"] = False

# --- Streamlit UI ä¸»é«” ---
st.set_page_config(page_title="MindForge", page_icon="ğŸ ", layout="wide")

# --- æ ¸å¿ƒä¿®æ”¹ 2: ä½¿ç”¨ä¸€å€‹çµ±ä¸€çš„å­—å…¸ä¾†å„²å­˜æ‰€æœ‰ç‹€æ…‹ ---
if 'tasks_status' not in st.session_state:
    st.session_state.tasks_status = {
        "synthesis": {"running": False, "progress": 0, "total": 0, "current_task": "", "logs": []},
        "inbox": {"running": False, "message": "", "success": "", "error": "", "logs": []},
        "review": {"running": False, "message": "", "success": "", "error": ""}
    }
if 'data_updated' not in st.session_state:
    st.session_state.data_updated = False

# é é¢æ¨™é¡Œå’Œä»‹ç´¹ (ä¸è®Š)
st.title("ğŸ§  MindForge - Your Cognition Forge")
st.markdown("Welcome! Use the tools below to capture and process information. Navigate to the **Dashboard** page in the sidebar to analyze your knowledge base.")
st.markdown("---")

# è¼‰å…¥è¨­å®šæª”ä¸¦åˆå§‹åŒ– (ä¸è®Š)
@st.cache_resource
def load_config_and_init():
    # ... (æ­¤å‡½å¼å…§å®¹å®Œå…¨ä¸è®Š)
    try:
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        st.error(f"âŒ è¼‰å…¥è¨­å®šæª” config.json å¤±æ•—: {e}")
        st.stop()
    provider = config.get("LLM_PROVIDER", "local")
    if provider == "local":
        local_api_url = config.get("LOCAL_CONFIG", {}).get("LLM_API_BASE_URL", "http://localhost:11434")
        with st.spinner("ğŸ©º æ­£åœ¨æª¢æŸ¥æœ¬åœ° Ollama æœå‹™ç‹€æ…‹..."):
            if not check_and_start_ollama(local_api_url):
                st.error("âŒ ç„¡æ³•å•Ÿå‹•æˆ–é€£æ¥åˆ°æœ¬åœ° Ollama æœå‹™ã€‚è«‹æ‰‹å‹•æª¢æŸ¥ã€‚")
                st.stop()
    return config

CONFIG = load_config_and_init()
if not CONFIG:
    st.stop()

provider_display = {"local": "ğŸ’» æœ¬åœ°æ¨¡å¼ (Local)", "cloud": "â˜ï¸ é›²ç«¯æ¨¡å¼ (Cloud)"}.get(CONFIG.get("LLM_PROVIDER"), "æœªçŸ¥")
st.info(f"ç•¶å‰é‹è¡Œæ¨¡å¼: **{provider_display}**")

# --- 1. Quick Add to Inbox ---
st.header("ğŸ“¥ Quick Add to Inbox")

# --- æ ¸å¿ƒä¿®æ”¹ 3: å¾æ–°çš„ tasks_status çµæ§‹ä¸­è®€å–ç‹€æ…‹ ---
inbox_status = st.session_state.tasks_status["inbox"]
if inbox_status["running"]:
    st.info(f"â³ {inbox_status['message']}")
elif inbox_status["success"]:
    st.success(inbox_status["success"])
    inbox_status["success"] = ""
elif inbox_status["error"]:
    st.error(inbox_status["error"])
    inbox_status["error"] = ""

tab1, tab2, tab3 = st.tabs(["âœï¸ Add Text/Idea", "ğŸ”— Add URL", "ğŸ–¼ï¸ Add Image (OCR)"])
is_task_running = any(st.session_state.tasks_status[task]["running"] for task in st.session_state.tasks_status)

with tab1:
    text_input = st.text_area("Content:", height=200, placeholder="Paste your articles, notes, meeting minutes, or fleeting ideas here...")
    if st.button("Add Text", key="add_text", disabled=is_task_running):
        if text_input:
            # --- æ ¸å¿ƒä¿®æ”¹ 4: é‡ç½®ç‹€æ…‹å­—å…¸ä¸¦å°‡å…¶ä½œç‚ºåƒæ•¸å‚³é ---
            st.session_state.tasks_status["inbox"] = {"running": True, "message": "æ­£åœ¨åˆå§‹åŒ–...", "success": "", "error": "", "logs": []}
            threading.Thread(target=background_add_to_inbox, args=(CONFIG, st.session_state.tasks_status["inbox"], 'text', text_input), daemon=True).start()
            st.rerun()
        else:
            st.warning("Please enter some content.")

with tab2:
    url_input = st.text_input("URL:", placeholder="https://example.com/article")
    if st.button("Add URL", key="add_url", disabled=is_task_running):
        if url_input:
            st.session_state.tasks_status["inbox"] = {"running": True, "message": "æ­£åœ¨åˆå§‹åŒ–...", "success": "", "error": "", "logs": []}
            threading.Thread(target=background_add_to_inbox, args=(CONFIG, st.session_state.tasks_status["inbox"], 'url', url_input), daemon=True).start()
            st.rerun()
        else:
            st.warning("Please enter a URL.")

with tab3:
    uploaded_file = st.file_uploader("Choose an image (screenshot, document photo...)", type=['png', 'jpg', 'jpeg'])
    if uploaded_file is not None:
        if st.button("Add Image", key="add_img", disabled=is_task_running):
            if not os.path.exists("data"): os.makedirs("data")
            temp_path = os.path.join("data", "temp_image.png")
            with open(temp_path, "wb") as f: f.write(uploaded_file.getbuffer())
            st.session_state.tasks_status["inbox"] = {"running": True, "message": "æ­£åœ¨åˆå§‹åŒ–...", "success": "", "error": "", "logs": []}
            threading.Thread(target=background_add_to_inbox, args=(CONFIG, st.session_state.tasks_status["inbox"], 'image', temp_path), daemon=True).start()
            st.rerun()

# --- 2. Knowledge Synthesis ---
st.header("âš™ï¸ Batch Processing & Synthesis")
st.subheader("Knowledge Synthesis")
st.markdown("Process items from your Notion Inbox with `New` status and convert them into structured knowledge nodes.")

synthesis_status = st.session_state.tasks_status["synthesis"]
if st.button("Run Knowledge Synthesis", disabled=is_task_running):
    st.session_state.tasks_status["synthesis"] = {"running": True, "progress": 0, "total": 0, "current_task": "æ­£åœ¨åˆå§‹åŒ–...", "logs": []}
    threading.Thread(target=background_knowledge_synthesis, args=(CONFIG, st.session_state.tasks_status["synthesis"]), daemon=True).start()
    st.rerun()

if synthesis_status["running"]:
    progress_value = synthesis_status["progress"] / synthesis_status["total"] if synthesis_status["total"] > 0 else 0
    st.progress(progress_value, text=f"é€²åº¦: {synthesis_status['progress']}/{synthesis_status['total']} - {synthesis_status['current_task']}")
    with st.expander("é¡¯ç¤ºè©³ç´°æ—¥èªŒ", expanded=True):
        log_container = st.container(height=300)
        for log in reversed(synthesis_status["logs"]):
            log_container.write(log)
    time.sleep(2)
    st.rerun()
elif synthesis_status["logs"]:
    # --- æ ¸å¿ƒä¿®æ”¹ 4: åœ¨ä»»å‹™çµæŸå¾Œï¼Œæª¢æŸ¥æˆåŠŸæ¨™è¨˜ä¸¦æ›´æ–° session_state ---
    # é€™å€‹å€å¡Šåªåœ¨ä»»å‹™å¾ running -> not running æ™‚åŸ·è¡Œä¸€æ¬¡
    if synthesis_status.get("synthesis_happened", False):
        st.session_state.data_updated = True
        st.toast("âœ… åˆæˆå®Œæˆï¼å„€è¡¨æ¿æ•¸æ“šå°‡åœ¨ä¸‹æ¬¡è¨ªå•æ™‚æ›´æ–°ã€‚")
        # é‡ç½®æ¨™è¨˜ï¼Œé¿å…ä¸å¿…è¦çš„é‡è¤‡è§¸ç™¼
        synthesis_status["synthesis_happened"] = False
        
    st.info("ä¸Šæ¬¡åˆæˆä»»å‹™å·²çµæŸã€‚")
    with st.expander("é¡¯ç¤ºä¸Šæ¬¡é‹è¡Œçš„è©³ç´°æ—¥èªŒ"):
        log_container = st.container(height=300)
        for log in reversed(synthesis_status["logs"]):
            log_container.write(log)

# --- 3. Trend Analysis & Review ---
st.header("ğŸ“Š Trend Analysis & Review")

review_status = st.session_state.tasks_status["review"]
if review_status["running"]:
    st.info(f"â³ {review_status['message']}")
elif review_status["success"]:
    st.success(review_status["success"])
    review_status["success"] = ""
elif review_status["error"]:
    st.error(review_status["error"])
    review_status["error"] = ""

period_option = st.selectbox("Select the period you want to review:", ("weekly", "monthly", "quarterly"), format_func=lambda x: x.capitalize())
if st.button(f"Generate {period_option.capitalize()} Trend Report", disabled=is_task_running):
    st.session_state.tasks_status["review"] = {"running": True, "message": "æ­£åœ¨åˆå§‹åŒ–...", "success": "", "error": ""}
    threading.Thread(target=background_run_review, args=(CONFIG, st.session_state.tasks_status["review"], period_option), daemon=True).start()
    st.rerun()

