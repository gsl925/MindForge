# pages/1_ðŸ“Š_Dashboard.py

import streamlit as st
import pandas as pd
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import json
from datetime import datetime
import tzlocal  # <--- å°Žå…¥æ–°çš„å¥—ä»¶

# å°Žå…¥æˆ‘å€‘è‡ªå·±çš„å‡½å¼
# Streamlit çš„å¤šé é¢æ‡‰ç”¨æœƒè‡ªå‹•è™•ç†è·¯å¾‘å•é¡Œ
from scripts.notion_handler import query_notion_database

# --- æ•¸æ“šåŠ è¼‰èˆ‡è™•ç† ---

@st.cache_data(ttl=600) # å¿«å–æ•¸æ“š 10 åˆ†é˜ï¼Œé¿å…é »ç¹è«‹æ±‚ Notion
def load_knowledge_data(config):
    """å¾ž Notion åŠ è¼‰æ‰€æœ‰çŸ¥è­˜ç¯€é»žä¸¦è½‰æ›ç‚º Pandas DataFrameã€‚"""
    print("Fetching data from Notion...")
    all_pages = query_notion_database(config['NOTION_TOKEN'], config['KNOWLEDGE_DB_ID'], filter_payload={}, debug_mode=config.get("DEBUG_MODE", False))
    
    if not all_pages:
        return pd.DataFrame()

    parsed_data = []
    for page in all_pages:
        props = page.get("properties", {})
        title_prop = props.get("Title", {}).get("title", [{}])
        title = title_prop[0].get("text", {}).get("content", "") if title_prop else "Untitled"
        
        category_prop = props.get("Category", {}).get("select", {})
        category = category_prop.get("name") if category_prop else "Uncategorized"
        
        tags_prop = props.get("Tags", {}).get("multi_select", [])
        tags = [tag.get("name") for tag in tags_prop]
        
        created_time = page.get("created_time")
        
        parsed_data.append({
            "title": title,
            "is_original": "ðŸ’¡" in title,
            "category": category,
            "tags": tags,
            "created_time": created_time
        })
        
    df = pd.DataFrame(parsed_data)
    # å°‡æ™‚é–“å­—ä¸²è½‰æ›ç‚ºå¯æ“ä½œçš„ datetime ç‰©ä»¶
    df['created_time'] = pd.to_datetime(df['created_time'])
    return df

# --- ä¸»æ‡‰ç”¨ç¨‹å¼ ---

st.set_page_config(page_title="MindForge Dashboard", layout="wide")
st.title("ðŸ“Š Knowledge Base Dashboard")

# --- æ ¸å¿ƒä¿®æ”¹ï¼šæª¢æŸ¥ session_state ä¸¦åœ¨éœ€è¦æ™‚æ¸…é™¤å¿«å– ---
if 'data_updated' not in st.session_state:
    st.session_state.data_updated = False

if st.session_state.data_updated:
    st.toast("ðŸ”„ æ•¸æ“šå·²æ›´æ–°ï¼Œæ­£åœ¨é‡æ–°åŠ è¼‰å„€è¡¨æ¿...")
    st.cache_data.clear()  # æ¸…é™¤æ‰€æœ‰ @st.cache_data çš„å¿«å–
    st.session_state.data_updated = False # é‡ç½®æ¨™è¨˜ï¼Œé¿å…ä¸å¿…è¦çš„é‡è¤‡åˆ·æ–°
# ----------------------------------------------------

# åŠ è¼‰è¨­å®šæª”
try:
    with open('config.json', 'r', encoding='utf-8') as f:
        CONFIG = json.load(f)
except FileNotFoundError:
    st.error("âŒ æ‰¾ä¸åˆ°è¨­å®šæª” `config.json`ã€‚è«‹ç¢ºä¿ä¸»æ‡‰ç”¨ç¨‹å¼ç›®éŒ„ä¸­æœ‰æ­¤æª”æ¡ˆã€‚")
    st.stop()

df = load_knowledge_data(CONFIG)

if df.empty:
    st.warning("æ‚¨çš„çŸ¥è­˜åº«ä¸­é‚„æ²’æœ‰ä»»ä½•æ•¸æ“šï¼")
    st.stop()

# --- å´é‚Šæ¬„ç¯©é¸å™¨ ---
st.sidebar.header("Filters")

# 1. æ™‚é–“ç¯„åœç¯©é¸å™¨
min_date = df['created_time'].min().date()
max_date = df['created_time'].max().date()
date_range = st.sidebar.date_input(
    "Select Date Range",
    value=(min_date, max_date),
    min_value=min_date,
    max_value=max_date
)

# 2. åˆ†é¡žç¯©é¸å™¨
all_categories = df['category'].unique()
selected_categories = st.sidebar.multiselect(
    "Select Categories",
    options=all_categories,
    default=all_categories
)

# --- æ‡‰ç”¨ç¯©é¸å™¨ ---
# å°‡å¾ž date_input å¾—åˆ°çš„ date ç‰©ä»¶è½‰æ›ç‚º pandas çš„ Timestampï¼Œä¸¦ç«‹å³è³¦äºˆ UTC æ™‚å€
start_date_filter = pd.to_datetime(date_range[0]).tz_localize('UTC')

# å°æ–¼çµæŸæ—¥æœŸï¼Œæˆ‘å€‘å…ˆæŠŠå®ƒè¨­ç½®ç‚ºç•¶å¤©çš„æœ€å¾Œä¸€ç§’ï¼Œç„¶å¾Œå†è³¦äºˆ UTC æ™‚å€
end_date_filter = pd.to_datetime(date_range[1]).replace(hour=23, minute=59, second=59).tz_localize('UTC')

filtered_df = df[
    (df['created_time'] >= start_date_filter) &
    (df['created_time'] <= end_date_filter) &
    (df['category'].isin(selected_categories))
]

if filtered_df.empty:
    st.warning("åœ¨é¸å®šçš„ç¯©é¸æ¢ä»¶ä¸‹æ²’æœ‰æ‰¾åˆ°ä»»ä½•æ•¸æ“šã€‚")
    st.stop()

# --- æ ¸å¿ƒæŒ‡æ¨™ (KPIs) ---
total_nodes = len(filtered_df)
original_ideas = filtered_df['is_original'].sum()
num_categories = filtered_df['category'].nunique()

col1, col2, col3 = st.columns(3)
col1.metric("Total Knowledge Nodes", total_nodes)
col2.metric("ðŸ’¡ Original Ideas", original_ideas)
col3.metric("Unique Categories", num_categories)

st.markdown("---")

# --- è¦–è¦ºåŒ–åœ–è¡¨ ---
col1, col2 = st.columns(2)

with col1:
    # 1. åˆ†é¡žåœ“é¤…åœ–
    st.subheader("Category Distribution")
    category_counts = filtered_df['category'].value_counts()
    fig_pie = px.pie(
        category_counts, 
        values=category_counts.values, 
        names=category_counts.index,
        title="Knowledge Nodes by Category"
    )
    st.plotly_chart(fig_pie, use_container_width=True)

    # 3. æ¨™ç±¤è©žé›²
    st.subheader("Popular Tags")
    all_tags = [tag for tags_list in filtered_df['tags'] for tag in tags_list]
    if all_tags:
        text = " ".join(all_tags)
        
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šæŒ‡å®šä¸­æ–‡å­—é«”è·¯å¾‘ ---
        # æ ¹æ“šæ‚¨çš„ä½œæ¥­ç³»çµ±é¸æ“‡åˆé©çš„è·¯å¾‘
        # å°æ–¼ Windows:
        font_path = "fonts/NotoSansTC-Regular.ttf"
        # å°æ–¼ macOS:
        # font_path = "/System/Library/Fonts/PingFang.ttc" 
        
        try:
            wordcloud = WordCloud(
                width=800, 
                height=400, 
                background_color='white',
                font_path=font_path  # <--- åœ¨é€™è£¡æŒ‡å®šå­—é«”
            ).generate(text)
            
            fig_wc, ax = plt.subplots()
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig_wc)
            
        except FileNotFoundError:
            st.error(f"å­—é«”æª”æ¡ˆæœªæ‰¾åˆ°: {font_path}")
            st.warning("è©žé›²ç„¡æ³•é¡¯ç¤ºä¸­æ–‡å­—å…ƒã€‚è«‹æª¢æŸ¥æ‚¨çš„ç³»çµ±ä¸­æ˜¯å¦å­˜åœ¨è©²å­—é«”ï¼Œæˆ–ä¿®æ”¹ç¨‹å¼ç¢¼ä¸­çš„ `font_path`ã€‚")
        except Exception as e:
            st.error(f"ç”Ÿæˆè©žé›²æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    else:
        st.info("No tags found in the selected data.")

with col2:
    # 2. è¶¨å‹¢æŸ±ç‹€åœ– (æŒ‰æœˆ)
    st.subheader("Nodes Added Over Time")
    nodes_per_month = filtered_df.set_index('created_time').resample('M').size().reset_index(name='count')
    nodes_per_month['created_time'] = nodes_per_month['created_time'].dt.strftime('%Y-%m')
    fig_bar = px.bar(
        nodes_per_month, 
        x='created_time', 
        y='count',
        title="Monthly Knowledge Creation Trend",
        labels={'created_time': 'Month', 'count': 'Number of Nodes'}
    )
    st.plotly_chart(fig_bar, use_container_width=True)

st.markdown("---")

# --- åŽŸå§‹æ•¸æ“šè¡¨æ ¼ ---
st.subheader("Filtered Data")

# è¤‡è£½ä¸€ä»½ DataFrame ä»¥å…å½±éŸ¿åŽŸå§‹æ•¸æ“š
display_df = filtered_df.copy()

# --- æ ¸å¿ƒä¿®æ”¹ï¼šå‹•æ…‹ç²å–æœ¬åœ°æ™‚å€ä¸¦é€²è¡Œè½‰æ› ---
try:
    # 1. è‡ªå‹•åµæ¸¬æœ¬åœ°æ™‚å€åç¨± (ä¾‹å¦‚ 'Asia/Taipei')
    local_tz_name = tzlocal.get_localzone_name()
    st.info(f"åµæ¸¬åˆ°æœ¬åœ°æ™‚å€: {local_tz_name}ï¼Œæ­£åœ¨é€²è¡Œæ™‚é–“è½‰æ›...")

    # 2. å°‡ 'created_time' æ¬„ä½å¾ž UTC è½‰æ›åˆ°åµæ¸¬åˆ°çš„æœ¬åœ°æ™‚å€
    display_df['created_time'] = display_df['created_time'].dt.tz_convert(local_tz_name)

except Exception as e:
    st.warning(f"è‡ªå‹•æ™‚å€è½‰æ›å¤±æ•—: {e}")
    st.info("å°‡ç¹¼çºŒé¡¯ç¤º UTC æ™‚é–“ã€‚æ‚¨å¯ä»¥å˜—è©¦æ‰‹å‹•åœ¨ç¨‹å¼ç¢¼ä¸­æŒ‡å®šæ™‚å€ï¼Œä¾‹å¦‚ 'Asia/Taipei'ã€‚")

# ç‚ºäº†æ›´å¥½çš„å¯è®€æ€§ï¼Œæ ¼å¼åŒ–æ™‚é–“å­—ä¸² (ä¸¦ç§»é™¤æ™‚å€è³‡è¨Š)
# æˆ‘å€‘å¯ä»¥åœ¨æ ¼å¼åŒ–ä¹‹å‰ï¼Œå…ˆç”¨ tz_localize(None) ç§»é™¤æ™‚å€è³‡è¨Šï¼Œè®“ strftime æ›´ä¹¾æ·¨
display_df['created_time'] = display_df['created_time'].dt.tz_localize(None).dt.strftime('%Y-%m-%d %H:%M:%S')

# é¡¯ç¤ºè™•ç†éŽçš„ DataFrame
st.dataframe(display_df)
