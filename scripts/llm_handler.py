# scripts/llm_handler.py (æ”¯æ´æœ¬åœ°èˆ‡é›²ç«¯é›™æ¨¡å¼)
import requests
import json
import re

def query_llm(system_prompt: str, user_prompt: str, config: dict, use_json_format: bool = True) -> str:
    """
    æ ¹æ“šè¨­å®šï¼Œå‘æœ¬åœ°æˆ–é›²ç«¯ Ollama æœå‹™ç™¼é€è«‹æ±‚ã€‚
    """
    provider = config.get("LLM_PROVIDER", "local")
    debug_mode = config.get("DEBUG_MODE", False) # è®€å–åµéŒ¯æ¨¡å¼é–‹é—œ

    if provider == "cloud":
        print("â˜ï¸ æ­£åœ¨ä½¿ç”¨ Ollama Cloud...")
        # é›²ç«¯æ¨¡å¼é€šå¸¸æ¯”è¼ƒç©©å®šï¼Œæš«ä¸ç‚ºå…¶æ·»åŠ è¤‡é›œçš„åµéŒ¯æ—¥èªŒ
        return query_ollama_cloud(system_prompt, user_prompt, config.get("CLOUD_CONFIG", {}), use_json_format)
    else:
        # å°‡ debug_mode å‚³éçµ¦æœ¬åœ°è™•ç†å‡½å¼
        return query_ollama_local(system_prompt, user_prompt, config.get("LOCAL_CONFIG", {}), use_json_format, debug_mode)

def query_ollama_cloud(system_prompt: str, user_prompt: str, cloud_config: dict, use_json_format: bool):
    """è™•ç†å° Ollama Cloud API çš„å‘¼å« (ä½¿ç”¨æ–°ç‰ˆ /v1 API)ã€‚"""
    api_key = cloud_config.get("OLLAMA_API_KEY")
    model = cloud_config.get("LLM_MODEL_NAME")
    api_url = "https://ollama.com/v1/chat/completions"

    if not api_key or "YOUR_OLLAMA_CLOUD_API_KEY" in api_key:
        print("âŒ éŒ¯èª¤ï¼šOllama Cloud API é‡‘é‘°æœªè¨­å®šã€‚è«‹åœ¨ config.json ä¸­å¡«å¯«ã€‚")
        return None

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    }
    
    if use_json_format:
        payload["response_format"] = {"type": "json_object"}

    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload), timeout=600)
        response.raise_for_status()
        response_data = response.json()
        content = response_data['choices'][0]['message']['content']
        return content
    except requests.exceptions.RequestException as e:
        print(f"âŒ èˆ‡ Ollama Cloud é€£æ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\n   éŒ¯èª¤è©³æƒ…: {response.text}")
        return None
    except (KeyError, IndexError) as e:
        print(f"âŒ è§£æ Ollama Cloud å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\n   æ”¶åˆ°çš„åŸå§‹å›æ‡‰: {response.text}")
        return None

def query_ollama_local(system_prompt: str, user_prompt: str, local_config: dict, use_json_format: bool, debug_mode: bool = False):
    """è™•ç†å°æœ¬åœ° Ollama çš„å‘¼å«ï¼Œä¸¦æ ¹æ“š debug_mode æ±ºå®šæ˜¯å¦æ‰“å°è©³ç´°æ—¥èªŒã€‚"""
    api_url = local_config.get("LLM_API_BASE_URL")
    model = local_config.get("LLM_MODEL_NAME")
    generate_url = f"{api_url}/api/generate"
    full_prompt = f"{system_prompt}\n\n{user_prompt}"

    payload = {"model": model, "prompt": full_prompt, "stream": False}
    if use_json_format:
        payload["format"] = "json"

    if debug_mode:
        print(f"ğŸ [åµéŒ¯æ¨¡å¼] æ­£åœ¨ä½¿ç”¨æ¨¡å‹ '{model}' é€é API: {generate_url}")
    else:
        print(f"ğŸ’» æ­£åœ¨ä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹ '{model}'...")

    try:
        response = requests.post(generate_url, data=json.dumps(payload), timeout=120)
        response.raise_for_status()
        
        response_text = response.text.strip()
        last_json_str = next((line for line in reversed(response_text.splitlines()) if line.strip()), None)
        
        if not last_json_str:
            if debug_mode: print("ğŸ [åµéŒ¯æ¨¡å¼] AI æ¨¡å‹è¿”å›çš„åŸå§‹ HTTP å›æ‡‰ç‚ºç©ºæˆ–ç„¡æ•ˆã€‚")
            return None

        response_data = json.loads(last_json_str)
        content = response_data.get('response', '')

        if debug_mode:
            print("\n" + "="*20 + " [åµéŒ¯æ¨¡å¼] AI åŸå§‹å›æ‡‰ " + "="*20)
            print(f"æ”¶åˆ°çš„å…§å®¹é•·åº¦: {len(content)} å­—å…ƒ")
            print("--- å…§å®¹é–‹å§‹ ---")
            print(content)
            print("--- å…§å®¹çµæŸ ---")
            print("="*61 + "\n")

        if not content.strip():
            print("\nâŒ åš´é‡éŒ¯èª¤ï¼šæœ¬åœ° AI æ¨¡å‹è¿”å›äº†ç©ºå…§å®¹ï¼å¾ˆå¯èƒ½æ˜¯ç¡¬é«”è³‡æºä¸è¶³ã€‚è«‹å˜—è©¦æ›´æ›ä¸€å€‹æ›´å°çš„æ¨¡å‹ã€‚\n")
            return None

        if use_json_format:
            match = re.search(r'\{.*\}', content, re.DOTALL)
            if match:
                return match.group(0)
            else:
                if debug_mode: print("ğŸ [åµéŒ¯æ¨¡å¼] åœ¨ AI å›æ‡‰ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON çµæ§‹ã€‚")
                return None
        return content
        
    except requests.exceptions.RequestException as e:
        if debug_mode: print(f"ğŸ [åµéŒ¯æ¨¡å¼] èˆ‡æœ¬åœ° Ollama é€£æ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        raise e
    except (json.JSONDecodeError, KeyError, IndexError, ValueError) as e:
        if debug_mode: print(f"ğŸ [åµéŒ¯æ¨¡å¼] è§£ææœ¬åœ° Ollama åŸå§‹å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\n   æ”¶åˆ°çš„åŸå§‹å›æ‡‰: {response.text}")
        return None
